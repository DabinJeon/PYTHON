{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt=Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나', '는', '데이터', '분석', '을', '배운다']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token=okt.morphs(\"나는 데이터 분석을 배운다\")\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나': 0, '는': 1, '데이터': 2, '분석': 3, '을': 4, '배운다': 5}\n"
     ]
    }
   ],
   "source": [
    "word2index={}\n",
    "for v in token:\n",
    "    if v not in word2index.keys():\n",
    "        word2index[v]=len(word2index)\n",
    "print(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#원핫 인코딩\n",
    "\n",
    "def ohe(word,word2index):\n",
    "    ohv=[0]*(len(word2index)) #[0]을 길기만큼 반복\n",
    "    print(ohv)\n",
    "    index=word2index[word]\n",
    "    ohv[index]=1 #2번째 인덱스 값을 1로 변경\n",
    "    return ohv\n",
    "\n",
    "ohe(\"데이터\",word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopword 처리 (불용어 처리) : 의미 없는 단어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"n't\", 'know']\n"
     ]
    }
   ],
   "source": [
    "ex=\"I don't know where it is\"\n",
    "sw=stopwords.words(\"english\")\n",
    "word_tokens=word_tokenize(ex)\n",
    "\n",
    "res=[]\n",
    "for w in word_tokens:\n",
    "    if w not in sw:\n",
    "        res.append(w)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오늘은', '금요일', '입니다', '.', '졸면', '.', '오늘만']\n"
     ]
    }
   ],
   "source": [
    "ex=\"오늘은 금요일 입니다. 졸면 안 돼. 오늘만 참자\"\n",
    "stop_words=\"안 돼 참자\"\n",
    "sw=stop_words.split(\" \")\n",
    "word_tokens=word_tokenize(ex)\n",
    "\n",
    "res=[]\n",
    "for w in word_tokens:\n",
    "    if w not in sw:\n",
    "        res.append(w)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>메일제목</th>\n",
       "      <th>스팸여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>형님 어제 나이트 왜 안왔어요?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>절호의 찬스, 놓치면 평생 휘회</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>잘 지냈어요? 오랜만</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                메일제목  스팸여부\n",
       "0  형님 어제 나이트 왜 안왔어요?     1\n",
       "1  절호의 찬스, 놓치면 평생 휘회     1\n",
       "2        잘 지냈어요? 오랜만     0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mail=[\n",
    "    ['형님 어제 나이트 왜 안왔어요?',1],\n",
    "    ['절호의 찬스, 놓치면 평생 휘회',1],\n",
    "    ['잘 지냈어요? 오랜만',0]]\n",
    "col=['메일제목','스팸여부']\n",
    "df=pd.DataFrame(mail,columns=col)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오늘은 초여름의 날씨를 볼 수 있겠습니다'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token=re.sub(\"(\\.)\",\"\",\"오늘은 초여름의 날씨를 볼 수 있겠습니다.\") #점기호 삭제\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt=Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['오늘', '은', '초여름', '의', '날씨', '를', '볼', '수', '있겠습니다']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toekn=okt.morphs(token)\n",
    "toekn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'오': 0, '늘': 1, '은': 2, ' ': 3, '초': 4, '여': 5, '름': 6, '의': 7, '날': 8, '씨': 9, '를': 10, '볼': 11, '수': 12, '있': 13, '겠': 14, '습': 15, '니': 16, '다': 17}\n",
      "[1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "w2i={}\n",
    "BOW=[]\n",
    "\n",
    "for v in token:\n",
    "    if v not in w2i.keys():\n",
    "        w2i[v]=len(w2i)\n",
    "        BOW.insert(len(w2i)-1,1)\n",
    "    else:\n",
    "        i=w2i.get(v)\n",
    "        BOW[i]=BOW[i]+1\n",
    "print(w2i)\n",
    "print(BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 2, 1, 2, 1]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=[\"you know I want your love. becaues I love you.\"]\n",
    "\n",
    "vector=CountVectorizer() #두 글자 이상에 대해서만 생성 (i 는 제외됨)\n",
    "vector.fit_transform(text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'becaues': 0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 2, 1, 2, 1]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect=CountVectorizer(stop_words=['the','a','an','not','is'])\n",
    "test=[\"Family is not an important thing. It's everything.\"]\n",
    "\n",
    "vect.fit_transform(text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 1 0 1 1]\n",
      " [0 0 1 0 0 0 0 1 0]\n",
      " [1 0 0 0 1 0 1 0 0]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "text=[\n",
    "      \"you know I want your love\",\n",
    "      \"I like you\",\n",
    "      \"what should I do\"\n",
    "]\n",
    "\n",
    "vector=CountVectorizer()\n",
    "print(vector.fit_transform(text).toarray())\n",
    "print(vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46735098 0.         0.46735098 0.         0.46735098\n",
      "  0.         0.35543247 0.46735098]\n",
      " [0.         0.         0.79596054 0.         0.         0.\n",
      "  0.         0.60534851 0.        ]\n",
      " [0.57735027 0.         0.         0.         0.57735027 0.\n",
      "  0.57735027 0.         0.        ]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "text=[\n",
    "      \"you know I want your love\",\n",
    "      \"I like you\",\n",
    "      \"what should I do\"\n",
    "]\n",
    "\n",
    "tfidf=TfidfVectorizer().fit(text)\n",
    "\n",
    "print(tfidf.fit_transform(text).toarray())\n",
    "print(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
